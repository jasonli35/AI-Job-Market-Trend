{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               title          location  \\\n",
      "0                                     AI/ML Engineer      New York, NY   \n",
      "1                  Software Engineer - AI/ML Systems  Redwood City, CA   \n",
      "2                         ML Engineer at 100% Remote      San Jose, CA   \n",
      "3  Machine Learning Engineer (L4) - Infrastructur...     Los Gatos, CA   \n",
      "4                       Data Scientist / ML Engineer  Redwood City, CA   \n",
      "\n",
      "  publishedAt      companyName  \\\n",
      "0  2024-05-29           Wesper   \n",
      "1         NaN       Snorkel AI   \n",
      "2  2024-06-01  ELITE MENTE LLC   \n",
      "3  2024-05-19          Netflix   \n",
      "4         NaN   Paradyme, Inc.   \n",
      "\n",
      "                                         description  \\\n",
      "0  THE OPPORTUNITY\\n\\nWesper is looking for a sma...   \n",
      "1  We're on a mission to democratize AI by buildi...   \n",
      "2  Hello ,\\n\\nHope you are doing well!\\n\\nPlease ...   \n",
      "3  At Netflix our goal is to entertain the world....   \n",
      "4  Overview\\n\\nParadyme Management is a rapidly g...   \n",
      "\n",
      "                  applicationsCount contractType   experienceLevel  \\\n",
      "0               Over 200 applicants    Full-time  Mid-Senior level   \n",
      "1                     51 applicants    Full-time       Entry level   \n",
      "2  Be among the first 25 applicants    Full-time       Entry level   \n",
      "3               Over 200 applicants    Full-time    Not Applicable   \n",
      "4                    110 applicants    Full-time       Entry level   \n",
      "\n",
      "                                 workType  \\\n",
      "0  Engineering and Information Technology   \n",
      "1  Engineering and Information Technology   \n",
      "2  Engineering and Information Technology   \n",
      "3  Engineering and Information Technology   \n",
      "4  Engineering and Information Technology   \n",
      "\n",
      "                                              sector  applicationsCount_int  \n",
      "0                                Internet Publishing                    425  \n",
      "1                               Software Development                     51  \n",
      "2                            Staffing and Recruiting                     12  \n",
      "3  Entertainment Providers, Technology, Informati...                    425  \n",
      "4                      IT Services and IT Consulting                    110  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "file_path = 'ai_ml_jobs_linkedin.csv'\n",
    "# ai_linkedIn_data = pd.read_csv(file_path, encoding='latin1')\n",
    "ai_linkedIn_data = pd.read_csv('ai_ml_jobs_linkedin.csv')\n",
    "print(ai_linkedIn_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_linkedIn_data['applicationsCount_int'] = ai_linkedIn_data['applicationsCount'].str.extract('(\\d+)')\n",
    "\n",
    "ai_linkedIn_data['applicationsCount_int'] = ai_linkedIn_data['applicationsCount_int'].astype(int)\n",
    "#convert all application with count 25 to 12\n",
    "\n",
    "ai_linkedIn_data.loc[ai_linkedIn_data['applicationsCount_int'] == 25, 'applicationsCount_int'] = 13\n",
    "#conver applicaitonCount of 200 to 425\n",
    "ai_linkedIn_data.loc[ai_linkedIn_data['applicationsCount_int'] == 200, 'applicationsCount_int'] = 425\n",
    "#write count back to csv file\n",
    "ai_linkedIn_data.to_csv('ai_ml_jobs_linkedin.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164\n"
     ]
    }
   ],
   "source": [
    "#change location to one hot encoding\n",
    "ai_linkedIn_data['location'] = ai_linkedIn_data['location'].str.lower()\n",
    "# do one-hot encoding based on location name\n",
    "\n",
    "one_hot_encoded = pd.get_dummies(ai_linkedIn_data['location'])\n",
    "\n",
    "# Combine one-hot encoded columns into a single vector column\n",
    "ai_linkedIn_data['location_one_hot'] = one_hot_encoded.apply(lambda row: row.values.tolist(), axis=1)\n",
    "\n",
    "#do one hot encoding for location as a vector column\n",
    "\n",
    "\n",
    "print(len(ai_linkedIn_data['location_one_hot'][0]))\n",
    "#write back to csv file with new column name location_one_hot\n",
    "ai_linkedIn_data.to_csv('ai_ml_jobs_linkedin.csv', index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "company count  520\n"
     ]
    }
   ],
   "source": [
    "#change location to one hot encoding\n",
    "ai_linkedIn_data['companyName'] = ai_linkedIn_data['companyName'].str.lower()\n",
    "# do one-hot encoding based on location name\n",
    "\n",
    "company_one_hot_encoded = pd.get_dummies(ai_linkedIn_data['companyName'])\n",
    "\n",
    "# Combine one-hot encoded columns into a single vector column\n",
    "ai_linkedIn_data['company_name_one_hot'] = company_one_hot_encoded.apply(lambda row: row.values.tolist(), axis=1)\n",
    "#see the company name to it unit one hot encoding. I mean a list of company name to one hot encoding matching\n",
    "\n",
    "\n",
    "\n",
    "print(\"company count \", len(ai_linkedIn_data['company_name_one_hot'][1]) + 1)\n",
    "#write back to csv file with new column name location_one_hot\n",
    "ai_linkedIn_data.to_csv('ai_ml_jobs_linkedin.csv', index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contract type count count  6\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "ai_linkedIn_data['contractType'] = ai_linkedIn_data['contractType'].str.lower()\n",
    "# do one-hot encoding based on location name\n",
    "\n",
    "contract_one_hot_encoded = pd.get_dummies(ai_linkedIn_data['contractType'])\n",
    "\n",
    "# Combine one-hot encoded columns into a single vector column\n",
    "ai_linkedIn_data['contract_one_hot_encoded'] = contract_one_hot_encoded.apply(lambda row: row.values.tolist(), axis=1)\n",
    "#see the company name to it unit one hot encoding. I mean a list of company name to one hot encoding matching\n",
    "print(\"contract type count count \", len(ai_linkedIn_data['contract_one_hot_encoded'][0]) + 1)\n",
    "#write back to csv file with new column name location_one_hot\n",
    "ai_linkedIn_data.to_csv('ai_ml_jobs_linkedin.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ex_levl count count  8\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ai_linkedIn_data['experienceLevel'] = ai_linkedIn_data['experienceLevel'].str.lower()\n",
    "# do one-hot encoding based on location name\n",
    "\n",
    "ex_levl_one_hot_encoded = pd.get_dummies(ai_linkedIn_data['experienceLevel'])\n",
    "\n",
    "# Combine one-hot encoded columns into a single vector column\n",
    "ai_linkedIn_data['ex_levl_one_hot_encoded'] = ex_levl_one_hot_encoded.apply(lambda row: row.values.tolist(), axis=1)\n",
    "#see the company name to it unit one hot encoding. I mean a list of company name to one hot encoding matching\n",
    "print(\"ex_levl count count \", len(ai_linkedIn_data['ex_levl_one_hot_encoded'][0]) + 1)\n",
    "#write back to csv file with new column name location_one_hot\n",
    "ai_linkedIn_data.to_csv('ai_ml_jobs_linkedin.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "work type count count  56\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ai_linkedIn_data['workType'] = ai_linkedIn_data['workType'].str.lower()\n",
    "# do one-hot encoding based on location name\n",
    "\n",
    "work_type_one_hot_encoded = pd.get_dummies(ai_linkedIn_data['workType'])\n",
    "\n",
    "# Combine one-hot encoded columns into a single vector column\n",
    "ai_linkedIn_data['work_type_one_hot_encoded'] = work_type_one_hot_encoded.apply(lambda row: row.values.tolist(), axis=1)\n",
    "#see the company name to it unit one hot encoding. I mean a list of company name to one hot encoding matching\n",
    "print(\"work type count count \", len(ai_linkedIn_data['work_type_one_hot_encoded'][0]) + 1)\n",
    "#write back to csv file with new column name location_one_hot\n",
    "ai_linkedIn_data.to_csv('ai_ml_jobs_linkedin.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sector count count  157\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ai_linkedIn_data['sector'] = ai_linkedIn_data['sector'].str.lower()\n",
    "# do one-hot encoding based on location name\n",
    "\n",
    "sector_one_hot_encoded = pd.get_dummies(ai_linkedIn_data['sector'])\n",
    "\n",
    "# Combine one-hot encoded columns into a single vector column\n",
    "ai_linkedIn_data['sector_one_hot_encoded'] = sector_one_hot_encoded.apply(lambda row: row.values.tolist(), axis=1)\n",
    "#see the company name to it unit one hot encoding. I mean a list of company name to one hot encoding matching\n",
    "print(\"sector count count \", len(ai_linkedIn_data['sector_one_hot_encoded'][0]) + 1)\n",
    "#write back to csv file with new column name location_one_hot\n",
    "ai_linkedIn_data.to_csv('ai_ml_jobs_linkedin.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title count count  443\n"
     ]
    }
   ],
   "source": [
    "ai_linkedIn_data['title'] = ai_linkedIn_data['title'].str.lower()\n",
    "# do one-hot encoding based on location name\n",
    "\n",
    "title_one_hot_encoded = pd.get_dummies(ai_linkedIn_data['title'])\n",
    "\n",
    "# Combine one-hot encoded columns into a single vector column\n",
    "ai_linkedIn_data['title_one_hot_encoded'] = title_one_hot_encoded.apply(lambda row: row.values.tolist(), axis=1)\n",
    "#see the company name to it unit one hot encoding. I mean a list of company name to one hot encoding matching\n",
    "print(\"title count count \", len(ai_linkedIn_data['title_one_hot_encoded'][0]) + 1)\n",
    "#write back to csv file with new column name location_one_hot\n",
    "ai_linkedIn_data.to_csv('ai_ml_jobs_linkedin.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "time_stamp_for_nah = -9223372036854775808\n",
    "ai_linkedIn_data = pd.read_csv('ai_ml_jobs_linkedin.csv')\n",
    "ai_linkedIn_data['publishedAt'] = pd.to_datetime(ai_linkedIn_data['publishedAt'], errors='coerce')\n",
    "\n",
    "# ai_linkedIn_data['publishedAt'] = ai_linkedIn_data['publishedAt'].dt.strftime('%Y-%m-%d')\n",
    "#convert ai_linkedIn_data['publishedAt'] to numerical timestamp\n",
    "ai_linkedIn_data['timestamp'] = ai_linkedIn_data['publishedAt'].apply(lambda x: x.timestamp() if pd.notnull(x) else None)\n",
    "\n",
    "\n",
    "non_null_publishedAt = []\n",
    "for t_stamp in ai_linkedIn_data['timestamp']:\n",
    "    if pd.notnull(t_stamp):\n",
    "        non_null_publishedAt.append(t_stamp)\n",
    "\n",
    "\n",
    "average_publishedAt = sum(non_null_publishedAt)/len(non_null_publishedAt)\n",
    "ai_linkedIn_data['timestamp']\n",
    "#replace all null values with average_publishedAt\n",
    "ai_linkedIn_data['timestamp'] = ai_linkedIn_data['timestamp'].fillna(average_publishedAt)\n",
    "ai_linkedIn_data.to_csv('ai_ml_jobs_linkedin.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['title', 'location', 'publishedAt', 'companyName', 'description',\n",
      "       'applicationsCount', 'contractType', 'experienceLevel', 'workType',\n",
      "       'sector', 'applicationsCount_int', 'location_one_hot',\n",
      "       'company_name_one_hot', 'contract_one_hot_encoded',\n",
      "       'ex_levl_one_hot_encoded', 'work_type_one_hot_encoded',\n",
      "       'sector_one_hot_encoded', 'timestamp', 'title_one_hot_encoded'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#print all columns name for ai_linkedIn_data\n",
    "print(ai_linkedIn_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_linkedIn_data = pd.read_csv('ai_ml_jobs_linkedin.csv')\n",
    "type(ai_linkedIn_data['contract_one_hot_encoded'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cse158",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
